{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 1: Instalaci\u00f3n de librer\u00edas necesarias"
      ],
      "metadata": {
        "id": "OSwJFVpUyLQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaJcRUqfyN7E",
        "outputId": "98e18214-0245-41ef-c405-99008da85868"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 2: Importaciones"
      ],
      "metadata": {
        "id": "O3_K0HqcyPht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import torch"
      ],
      "metadata": {
        "id": "4wwii3cHyRxP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 3: Cargar modelo y tokenizer"
      ],
      "metadata": {
        "id": "s7LxIRz4ycxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilgpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400,
          "referenced_widgets": [
            "7df9b66dbcc84d09b306f246b8f181a1",
            "71a8970fe9134e10a9423004eb019e61",
            "fc566164672f472488ed02ec9a9b3626",
            "5dc12a66dfbb497eb701abc3f7a9e720",
            "2321fdc0f9f94cd2a657c95da0d0525c",
            "0ddfc7ec72a94ee2a742a61076dbf9fc",
            "958e91c2ad2e46e89110b6ce521d2c11",
            "d722958a3dc54bc182878955f16d6b40",
            "58b795cb84774838af296245148b39d2",
            "477c62450fe241968f1dcfee1146aece",
            "343f07a39f7f4081b98e76e9d6bec054",
            "7f8552292489436d8f1aab317807e1f6",
            "d0c815e6ab0e456eafc9097731f0d16a",
            "b2bb8e0c9599451c9dcb5903edd9c093",
            "4805f7aa4a2542b98d45b25fa3d4ef10",
            "56817e3a3a8f494895723f91605dabe5",
            "da62501490704f8b9156118fe2f9f792",
            "106d5b64282146ed8b1742f802b961fd",
            "5caed5b565e04aa3aec3d750365f572e",
            "0a00fd2c68e24aa7ac872b1848be6020",
            "9ae12fc79fe74c138d618700b59e45de",
            "b5a70080dd744002b96e98797a9a3aea",
            "d674bbe39a594c72923b1f6d4c811dc0",
            "11fb5c2542484ee7be5341cd16c3e8de",
            "952b312410554675a51019dbbcf345b1",
            "4c8f92a5782442c4b2d12a892491ebf0",
            "192139e289b6480ca8693acc08deefaa",
            "0242fea4ad30460fa6357b214bbf6450",
            "2aaa1cb67bff46fe92cbcf42375c42ea",
            "2aeb6fc7141b4aada5a64afd07853d4b",
            "3110a3f2bbb84d8da6d79503470fd9d5",
            "cdfe6544d4554ea4847ed6008a5af670",
            "cf332592d1e8463d9af2f51fbb0ed49e",
            "e509486a791d45fea6c52a13748fec16",
            "3ddce572aaf84fad84b59b7eb3a4bd1d",
            "6e2a4927736341a78b452868168644c7",
            "17df896ea4524fb8b0f7eb0b2804ff37",
            "9c1576f953924f0b905feb02830742d5",
            "80087040149b4fe0b8bf1ac737b114dc",
            "61edc8dc45bb401e918187b3efee0748",
            "35b6347c9d69469dad7cc2ad7934ab86",
            "2fc26aa7e8364dad84bfa40adee69868",
            "66cf9d3380854f17ae05fefa9f40a897",
            "a087e4b4bee444049ebaff569169b539",
            "37a2c4f102e44a0d8be748b254c7589f",
            "9d988048819746febb494cc0c7c217df",
            "cc25709cb6fa437c88dcca833ee9e290",
            "8c07c51787bd41c0866f11f1054b64d8",
            "d4a5519ecb054174838cd6bd1a06f0ce",
            "548406a4c2804197aea83e537151307b",
            "f9bd67deef0349d39ed2569ef88c0958",
            "f8cb15566f5148358183cccbd29a9b3f",
            "d7bb03bab0474f5e889ecf0b8db2e547",
            "e044a276130442f69c9ef44ff66d46db",
            "a785db551f3b4a15a72ecc19d62f8498",
            "b3e7c5eaa76f41059a90c0d776ad978a",
            "a91e2c4af54349409ea2f3af33e96ac8",
            "38627816999e4d30a3d6fbe5424243f4",
            "873baeffbf0b45dc9f54397d1ac58b19",
            "dc67af476ed942e19702248fe38e81db",
            "686cbfe793c1449d93abfe1cfbbdd53d",
            "b3d075dac69d4862a365e408bfc6a9af",
            "83a2b0874e004999b8467b833c1536a0",
            "aad318b96bf5447297c8a2363b5c8202",
            "a0b692ae79324717ab8ed70c7e29033a",
            "55a9543d6cec40dfb1b5ea3cf57de0f9",
            "ed0243a5ec67463a8bbb5158fa83dff7",
            "2d4d5fd239954c96bbf59373a3dbf656",
            "7655531df02b43649fc9646d8620d61b",
            "6abdf938a2f349508ade6b46828f276e",
            "4af1fefd553b4c5094a8d1b52c259a73",
            "8019fb91c347490fa2c10d0f272d29c9",
            "f54f27a164c041daa95208ea3b4a67b4",
            "ef725048ef58438c8a149db26540b809",
            "bfbccf1cebfb4e368f02f66bb9bc7e54",
            "e9a387d5857f43d6896f8f7c4b6c180b",
            "89efae0dd6fe43e8994ea675b4646c2a"
          ]
        },
        "id": "S60oOQguyem5",
        "outputId": "f35e671f-d297-4f54-d4d3-947ded2efd54"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7df9b66dbcc84d09b306f246b8f181a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f8552292489436d8f1aab317807e1f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d674bbe39a594c72923b1f6d4c811dc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e509486a791d45fea6c52a13748fec16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37a2c4f102e44a0d8be748b254c7589f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3e7c5eaa76f41059a90c0d776ad978a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed0243a5ec67463a8bbb5158fa83dff7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 4: Cargar el dataset conversacional"
      ],
      "metadata": {
        "id": "jQYf4N8qyfxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"daily_dialog\")\n",
        "texts = [dialog for dialog in dataset['train']['dialog'][:1000]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298,
          "referenced_widgets": [
            "f04220fd66d548b2b0418cfa54ee7503",
            "e1be58e270044d3985e22a970da3006d",
            "6a5a24e8d0bb4edbb6465842629fa060",
            "59ca99d77f4644298944630685a6ee83",
            "12e138a2cd1b4330910d44b326979df9",
            "a02bcc4a46004581ab3813602a890025",
            "b96ed6bd642e4d15b95f76e58c975bd1",
            "d9d480eecdbf4330860013f8b2ff7653",
            "5ae9b05d1f764193887bd3bd5ea51734",
            "9abf5f7de5594514963fae0c412ad37d",
            "798012680d554569ab2555fba798ac06",
            "4ead48a159d84072aa28238f7e8ab4a1",
            "fadc9b88f8e4434289d995bdcdd980a0",
            "a3b7879547e0416ea3dfec1166e7f281",
            "20c7b3d6c51e4b50a7bb32ba59615488",
            "cb0077e80725434e80335aa7d93c90f6",
            "f96a3330b18c4d7fb89050876015f3d6",
            "a7ad6494cfa64624b3de437d3e782c5b",
            "778bb763c15a4847967bab872f7562e3",
            "238e9ffa7c5d480b96b2eee82c9ce0c3",
            "2eab488086f2426db0329f67c6ec016e",
            "0de52a498de049dfb71684f3b9dd4a6e",
            "73a34a33dc654695a801d7fbe8f5d406",
            "771f359eb916405f853aba0b9c93f498",
            "2d8383a3d8c44f86ba627828f77bec5a",
            "f0d97b2374234ebfa9c2d88e8b4999f4",
            "f1ae211145714161be828551f289741b",
            "571e0d17a2594285ba8181cf487a9f31",
            "a8d962dd987149429ffe99e04003ee48",
            "ed1187ce83c647389d51529422502a3d",
            "194763843fe04cfa854069b02cf80f3b",
            "9c8fb47f50e94acfac0b46d875383ed5",
            "0b4f0b27d3634b789b80a1de047ee3f4",
            "7e5fe4bec8fd42658f80b9702b0425d4",
            "2d560ecd729542ab86ee99566556a545",
            "d7eeb958afa04ac7afb2a1a46e677fca",
            "144b6ac9b3604534b4774b52c96d168b",
            "a654fbc0f40f48c995645736e783fec2",
            "450b3d53ac414d20b03a72f5616f3f05",
            "32d17cf50f2340b2bc38070e0b10facf",
            "2ce89800f31d48ca85cdb78755d87b2d",
            "36e527b01ad746ee8aaadc5a5b1b9735",
            "0c0d71214c3b45a799c6858c0c32701e",
            "28f848a48c404a609675731eb3476318",
            "0f8f2ae97dde44a5ae0604137fa0095d",
            "a4146c4bcb7a4af79d62349f3cea01ef",
            "617bdb3989444166b49f19d15189d77c",
            "78bf0d1ddefc4aa08b6fac4b1fafedff",
            "e7f2fab3f98849ffaa4290c4157d141f",
            "9b083edbeeb24cdf944b8d4d7253c4a2",
            "f4f5f6d4f1b646e38db3812769d30b43",
            "1ac2eee6e5434df98f34772898ca5165",
            "f187c04eeb6044b697d2c3229b073672",
            "ea9bd1adbbb54ef584e0d242c7587499",
            "8494a72199df4aceb151c771c34ff299",
            "583968b72c214953b1db6eac99c51547",
            "93e36d7ec6824192bae072ceb2f3a29a",
            "44d62121078d49b5860c48f55d7e07a7",
            "cd2fc648e5614d419e6a8947ce5561e1",
            "ae6bca3d069d4f36a704b60ed7be9d84",
            "8f6b2ebb57e5421f95cf3923c001775b",
            "5b63e00ccaac45c0a8303f8b54ccd292",
            "7b6acb5ed67a4bc2842cf22d28ae365b",
            "bf8b03cc96cb4ffc8aa3e46cea2b0ba4",
            "91c6484e15f54e58a03396f8c72bae6d",
            "96c0c5c70e2440fd89a734d8a1f1642d"
          ]
        },
        "id": "J37779s8yhVC",
        "outputId": "b8ffd6ce-f711-4c6c-90b6-8bffc2a8f542"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/7.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f04220fd66d548b2b0418cfa54ee7503"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "daily_dialog.py:   0%|          | 0.00/4.85k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ead48a159d84072aa28238f7e8ab4a1"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for daily_dialog contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/daily_dialog.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/4.48M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73a34a33dc654695a801d7fbe8f5d406"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/11118 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e5fe4bec8fd42658f80b9702b0425d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f8f2ae97dde44a5ae0604137fa0095d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "583968b72c214953b1db6eac99c51547"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 5: Tokenizaci\u00f3n y conversi\u00f3n"
      ],
      "metadata": {
        "id": "H0u-i0xUyqUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_format(example):\n",
        "    tokens = tokenizer(\" \".join(example), truncation=True, padding=\"max_length\", max_length=128)\n",
        "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()  # <- esto es lo que faltaba\n",
        "    return tokens\n",
        "\n",
        "tokenized_dataset = dataset[\"train\"].select(range(1000)).map(tokenize_and_format, batched=False)\n",
        "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6f543c68571a4f29a9d18cc0550f9801",
            "e6bfe127abfb4f50abc0ea5894ba75f9",
            "b2e0c1d8ffbd4be19d863cda1f5c7d17",
            "c38d310e2f9a4164be6dd43284f6d52a",
            "9894707a0fa94a2f9cf949dfc22ba65a",
            "1dae497bceed4c67a954ea7e58f45e89",
            "c677c13f23d544ba8046d5fe6af11c0b",
            "dc09dacd18004cdc85c524e5cc73182f",
            "b96b1cf605514c5a8569caef3b1f0493",
            "0a708af60f28438ca916dc0373b1dbce",
            "67bc89c8ea304b75bef411ad1fcb445a"
          ]
        },
        "id": "JivzZ66iyrKg",
        "outputId": "cf285742-92f6-4e8a-84fe-cac6be058ceb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f543c68571a4f29a9d18cc0550f9801"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 6: Definir los par\u00e1metros del entrenamiento"
      ],
      "metadata": {
        "id": "boIWF6kHyt1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=2,\n",
        "    num_train_epochs=1,\n",
        "    save_steps=500,\n",
        "    logging_steps=100,\n",
        "    report_to=\"none\"  # <- Esto desactiva WandB correctamente\n",
        ")"
      ],
      "metadata": {
        "id": "UIl0sqy4yvZp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 7: Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "awkns6_LyyEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "Lb8LHRiPy1M0",
        "outputId": "e56d0034-9fba-40ef-f0fd-40bfade8ef49"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 00:39, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.169000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=0.03407485166750848, metrics={'train_runtime': 40.8742, 'train_samples_per_second': 24.465, 'train_steps_per_second': 12.233, 'total_flos': 32662093824000.0, 'train_loss': 0.03407485166750848, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 8: Guardar el modelo"
      ],
      "metadata": {
        "id": "4Ro8TFQvy28d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./trained_model\")\n",
        "tokenizer.save_pretrained(\"./trained_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50cjEsh-y4LW",
        "outputId": "5d1a09ea-2e8e-48fa-d38a-a098e1ff8807"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./trained_model/tokenizer_config.json',\n",
              " './trained_model/special_tokens_map.json',\n",
              " './trained_model/vocab.json',\n",
              " './trained_model/merges.txt',\n",
              " './trained_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r trained_model.zip trained_model/\n",
        "from google.colab import files\n",
        "files.download(\"trained_model.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "0h4pQ2dnaFdb",
        "outputId": "eaafecc7-5b0d-4e56-9857-774a26e6ae09"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: trained_model/ (stored 0%)\n",
            "  adding: trained_model/config.json (deflated 51%)\n",
            "  adding: trained_model/generation_config.json (deflated 24%)\n",
            "  adding: trained_model/model.safetensors (deflated 7%)\n",
            "  adding: trained_model/merges.txt (deflated 53%)\n",
            "  adding: trained_model/special_tokens_map.json (deflated 74%)\n",
            "  adding: trained_model/vocab.json (deflated 68%)\n",
            "  adding: trained_model/tokenizer_config.json (deflated 56%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dcaebbc1-1e22-4150-b813-18e1115c6e94\", \"trained_model.zip\", 304933389)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
